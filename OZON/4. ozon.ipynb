{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8150f7e",
   "metadata": {},
   "source": [
    "## 1) Написать SQL запрос чтобы получить дату 1 и 10 выполненного заказа каждого продавца. Из данных в CSV формате необходимо сделать таблицу в любой из SQL СУБД.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8348340",
   "metadata": {},
   "source": [
    "### Подключаемся к csv файлу для формирования SQL запросов через duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02946e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подключаем дакдакдб для скл запросов из ксв файла\n",
    "import pandas as pd, duckdb\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"Данные для задания по SQL.csv\", sep=';', encoding='cp1251')\n",
    "con = duckdb.connect()\n",
    "con.register('sales', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818189d",
   "metadata": {},
   "source": [
    "#### В датасете есть записи, где количество заказов отрицательное, рассматриваем как возвраты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = con.execute(\"\"\"\n",
    "                  \n",
    "-- В течение одного дня компания может совершить несколько заказов, подготавливаем агрегат с суммой заказов за день\n",
    "WITH agg_day_sum AS ( \n",
    "    SELECT\n",
    "        CompanyID as company_id,\n",
    "        FactDate as fact_date,   \n",
    "        SUM(Qty) AS day_qty  --складываем все заказы за день\n",
    "    FROM sales\n",
    "    GROUP BY 1, 2\n",
    "),\n",
    "-- считаем накопительную сумму с шагом в день по продавцу\n",
    "cum_sum AS ( \n",
    "    SELECT\n",
    "        company_id,\n",
    "        fact_date,\n",
    "        SUM(day_qty) OVER (PARTITION BY company_id ORDER BY fact_date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumsum_qty \n",
    "\n",
    "--сортируем по дате количество заказов в окне по компании\n",
    "    FROM agg_day_sum\n",
    ")\n",
    "SELECT                        -- 3) берём самую раннюю дату достижения порогов\n",
    "    company_id,\n",
    "    MIN(CASE WHEN cumsum_qty >= 1  THEN fact_date END)  AS firstSale,\n",
    "    MIN(CASE WHEN cumsum_qty >= 10 THEN fact_date END)  AS tenthSale\n",
    "FROM cum_sum\n",
    "GROUP BY company_id\n",
    "ORDER BY company_id\n",
    "\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d590a9",
   "metadata": {},
   "source": [
    "## 2) Рассчитать с какой даты должно начаться взимание платы за услугу по продавцам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d369f",
   "metadata": {},
   "source": [
    "Продавцы маркетплейса Y получают бесплатную услугу первые 10 месяцев пользования этой услуги, но они периодически эту услугу могут отключать и подключать заново.\n",
    "Оплата за услугу начинается взиматься только после 10 полных месяцев пользования услугой. \n",
    "Датой началом пользования услуги необходимо считать первое событие подключения услуги.\n",
    "\n",
    "Задача:\n",
    "Рассчитать с какой даты должно начаться взимание платы за услугу по продавцам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ba4161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>value</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-12 11:31:58.598823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-18 15:20:08.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-01 10:11:44.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-01 10:14:23.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-30 17:00:38.684091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42825</th>\n",
       "      <td>41979</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-19 07:52:10.433332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42826</th>\n",
       "      <td>41980</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-19 10:39:42.332804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42827</th>\n",
       "      <td>41981</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-19 07:15:16.024747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42828</th>\n",
       "      <td>41982</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-19 09:18:17.709383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42829</th>\n",
       "      <td>41983</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-19 09:47:51.845782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42830 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_id  value                  created_at\n",
       "0               1      0  2021-04-12 11:31:58.598823\n",
       "1               1      1  2022-01-18 15:20:08.607000\n",
       "2               2      1  2021-10-01 10:11:44.721200\n",
       "3               2      1  2021-10-01 10:14:23.059372\n",
       "4               2      1  2021-09-30 17:00:38.684091\n",
       "...           ...    ...                         ...\n",
       "42825       41979      1  2022-07-19 07:52:10.433332\n",
       "42826       41980      1  2022-07-19 10:39:42.332804\n",
       "42827       41981      1  2022-07-19 07:15:16.024747\n",
       "42828       41982      1  2022-07-19 09:18:17.709383\n",
       "42829       41983      1  2022-07-19 09:47:51.845782\n",
       "\n",
       "[42830 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle(\"данные для Python.pickle\")  # compression будет определён автоматически\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da03fa",
   "metadata": {},
   "source": [
    "\n",
    "1.ищем первое включение value = 1\n",
    "2.затем проходим по событиям и сверяемся с месячным шагом в 1 месяц\n",
    "3.как только наберём 10 полный шагов внутри активных интервалов, то возвращаем дату этого 10-го шагов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15898547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shela\\AppData\\Local\\Temp\\ipykernel_27492\\3713100080.py:88: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(calc)\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def calc(group: pd.DataFrame) -> pd.Timestamp:\n",
    "\n",
    "    # сортируем и превращаем в кортеж по которому можно итерироваться\n",
    "    events = group.sort_values(\"created_at\")[[\"value\", \"created_at\"]].to_records(index=False)\n",
    "\n",
    "# получаем первое включение услуги у компании first_on\n",
    "    first_on = None\n",
    "    for value, timestep in events:\n",
    "        if value == 1:\n",
    "            first_on = timestep\n",
    "            break\n",
    "        # если компания так и не включила вернем nat\n",
    "    if first_on is None:\n",
    "        return pd.NaT \n",
    "\n",
    "# Для каждой компании пройдемся по интервалам работы и будем включать или выключать статус active в зависимости от value\n",
    "\n",
    "    active = False\n",
    "    intervals = []\n",
    "    cur_time = None\n",
    "\n",
    "    for val, ts in events:\n",
    "        if ts < first_on:\n",
    "            # события до первого включения игнорируем\n",
    "            continue\n",
    "\n",
    "        if cur_time is None:\n",
    "            cur_time = first_on\n",
    "            active = True  \n",
    "\n",
    "        if ts == first_on:\n",
    "            # это по факту первое включение \n",
    "            continue\n",
    "\n",
    "# В список интервалов записывается start, end, is_active начиная с first_on\n",
    "        intervals.append((cur_time, ts, active))\n",
    "        # переключаем статус по событию\n",
    "        active = (val == 1)\n",
    "        cur_time = ts\n",
    "    \n",
    "    first_on = pd.Timestamp(first_on)   # привели к Timestamp\n",
    "\n",
    "    # Если у компании последняя запись это value = 1, то прибавляем к ней 10+ месяцев, чтобы получить дату закрытия\n",
    "    period_end = first_on + np.timedelta64(330, 'D')\n",
    "    intervals.append((cur_time, period_end, active))\n",
    "\n",
    "    # Теперь итеративно идем по интервалам и от первого включения считаем сколько полных месяцев\n",
    "    steps_needed = 10\n",
    "    steps_done = 0\n",
    "    k = 1\n",
    "    # пройдём по активным интервалам и засчитаем все тики, которые туда попадают\n",
    "    for start, end, is_active in intervals:\n",
    "        start = pd.Timestamp(start)\n",
    "        end = pd.Timestamp(end)\n",
    "\n",
    "        if not is_active:\n",
    "            continue\n",
    "        # print(f\"start {start}, end {end}, is_active {is_active}\")\n",
    "        # берём последовательность контрольных дат first_on + k месяцев, которые >= start и < end\n",
    "        while steps_done < steps_needed:\n",
    "            step = first_on + relativedelta(months=k)\n",
    "            # print(f\"step {step}\")\n",
    "\n",
    "            if step >= end:\n",
    "                break\n",
    "            if step >= start:\n",
    "                steps_done += 1\n",
    "                if steps_done == steps_needed:\n",
    "                    return step\n",
    "            k += 1\n",
    "\n",
    "        if steps_done == steps_needed:\n",
    "            break\n",
    "\n",
    "        if steps_done < steps_needed:\n",
    "            while first_on + relativedelta(months=k) < start:\n",
    "                k += 1\n",
    "        # print(step, steps_done)\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "# группируем по компаниям и каждой для каждой компании считаем дату оплаты подписки\n",
    "dates = (\n",
    "    df.groupby(\"company_id\", as_index=False)\n",
    "      .apply(calc)\n",
    "      .rename(columns={None: \"billing_start\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df22e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.to_pickle(\"billing_start.pkl\", protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
